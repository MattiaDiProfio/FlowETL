root INFO - 14/04/2025 11:59:49 AM : Connected to broker
kafka.consumer.subscription_state INFO - 14/04/2025 11:59:49 AM : Updated partition assignment: [TopicPartition(topic='optimalPlans', partition=0)]
kafka.conn INFO - 14/04/2025 11:59:49 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 14/04/2025 11:59:49 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 14/04/2025 11:59:49 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 14/04/2025 12:01:28 PM : Received optimal plan -> ['students_grades_source.json', {'associated_key': None}, {'standardiseFeatures': '```python\n{\n    ("Midterm_Score",): ("midterm_score",),\n    ("Quizzes_Avg",): ("quizzes_avg",),\n    ("Extracurricular_Activities",): ("takes_extracurriculars",),\n    ("Parent_Education_Level",): ("Parent_Education_Level",),\n    ("Stress_Level (1-10)",): ("Stress_Level (1-10)",),\n    ("Family_Income_Level",): ("Family_Income_Level",),\n    ("Email",): ("student_email",),\n    ("First_Name", "Last_Name"): ("full_name",),\n    ("Total_Score",): ("student_total_score",),\n    ("Study_Hours_per_Week",): ("weekly_study_hours",),\n    ("Gender",): ("student_gender",),\n    ("Sleep_Hours_per_Night",): ("Sleep_Hours_per_Night",),\n    ("Final_Score",): ("final_score",),\n    ("Grade",): ("grade",),\n    ("Attendance (%)",): ("attendance_percent",),\n    ("Age",): ("student_age",),\n    ("Assignments_Avg",): ("assignments_avg",),\n    ("Internet_Access_at_Home",): ("has_home_internet",),\n    ("Projects_Score",): ("projects_score",),\n    ("Student_ID",): ("student_id",),\n    ("Department",): ("dept",),\n    ("Participation_Score",): ()\n}\n```'}, 'missingValues/impute', 'duplicates', 'outliers/impute', {'standardiseValues': '```python\ndef transform_table(input_table):\n    # Extract headers and data rows\n    headers = input_table[0]\n    data = input_table[1:]\n    \n    # Create a map for easy column index lookup\n    col_map = {col: idx for idx, col in enumerate(headers)}\n    \n    # Initialize output table with the first row (headers) from output_table\n    output_data = []\n    \n    for row in data:\n        new_row = []\n        \n        # Process each column based on input data\n        \n        # midterm_score - direct mapping\n        new_row.append(row[col_map[\'midterm_score\']])\n        \n        # quizzes_avg - direct mapping\n        new_row.append(row[col_map[\'quizzes_avg\']])\n        \n        # takes_extracurriculars - convert to binary (0/1)\n        extracurricular = 1 if row[col_map[\'takes_extracurriculars\']] == \'Yes\' else 0\n        new_row.append(extracurricular)\n        \n        # Parent_Education_Level - direct mapping, handle None values\n        parent_edu = row[col_map[\'Parent_Education_Level\']]\n        if parent_edu == \'None\' or parent_edu is None:\n            parent_edu = "None"\n        new_row.append(parent_edu)\n        \n        # Stress_Level (1-10) - direct mapping\n        new_row.append(row[col_map[\'Stress_Level (1-10)\']])\n        \n        # Family_Income_Level - direct mapping\n        new_row.append(row[col_map[\'Family_Income_Level\']])\n        \n        # student_email - direct mapping\n        new_row.append(row[col_map[\'student_email\']])\n        \n        # full_name - combine first and last name\n        full_name_parts = row[col_map[\'full_name\']].split(\'|\')\n        full_name = f"{full_name_parts[0]} {full_name_parts[1]}"\n        new_row.append(full_name)\n        \n        # student_total_score - direct mapping\n        new_row.append(row[col_map[\'student_total_score\']])\n        \n        # weekly_study_hours - direct mapping\n        new_row.append(row[col_map[\'weekly_study_hours\']])\n        \n        # student_gender - direct mapping\n        new_row.append(row[col_map[\'student_gender\']])\n        \n        # Sleep_Hours_per_Night - direct mapping\n        new_row.append(row[col_map[\'Sleep_Hours_per_Night\']])\n        \n        # final_score - direct mapping\n        new_row.append(row[col_map[\'final_score\']])\n        \n        # grade - direct mapping\n        new_row.append(row[col_map[\'grade\']])\n        \n        # attendance_percent - direct mapping\n        new_row.append(row[col_map[\'attendance_percent\']])\n        \n        # student_age - direct mapping\n        new_row.append(row[col_map[\'student_age\']])\n        \n        # assignments_avg - direct mapping, can be None\n        new_row.append(row[col_map[\'assignments_avg\']])\n        \n        # has_home_internet - convert to binary (1/0)\n        has_internet = 1 if row[col_map[\'has_home_internet\']] == \'Yes\' else 0\n        new_row.append(has_internet)\n        \n        # projects_score - direct mapping\n        new_row.append(row[col_map[\'projects_score\']])\n        \n        # student_id - direct mapping\n        new_row.append(row[col_map[\'student_id\']])\n        \n        # dept - direct mapping\n        new_row.append(row[col_map[\'dept\']])\n        \n        output_data.append(new_row)\n    \n    return output_data\n```'}]
root INFO - 14/04/2025 12:01:29 PM : Published the following metrics to Reporter : {'from': 'pre_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 1.754}, 'outliers': {'numerical_outliers_percent': 0.0}, 'duplicates': {'duplicate_rows_percent': 0.02}, 'dq': 0.994}}
kafka.conn INFO - 14/04/2025 12:01:29 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 14/04/2025 12:01:29 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 14/04/2025 12:01:29 PM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 14/04/2025 12:01:29 PM : Applied plan to file 'input\source\students_grades_source.json'
root INFO - 14/04/2025 12:01:29 PM : Successfully loaded the transformed file to '\output'
root INFO - 14/04/2025 12:01:30 PM : Published the following metrics to Reporter : {'from': 'post_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 0.0}, 'outliers': {'numerical_outliers_percent': 0.0}, 'duplicates': {'duplicate_rows_percent': 0.02}, 'dq': 1.0}}
kafka.producer.kafka INFO - 14/04/2025 12:01:30 PM : Closing the Kafka producer with 4294967.0 secs timeout.
kafka.conn INFO - 14/04/2025 12:01:30 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
kafka.conn INFO - 14/04/2025 12:01:30 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
