root INFO - 14/04/2025 11:36:25 AM : Connected to broker
kafka.consumer.subscription_state INFO - 14/04/2025 11:36:25 AM : Updated partition assignment: [TopicPartition(topic='optimalPlans', partition=0)]
kafka.conn INFO - 14/04/2025 11:36:25 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 14/04/2025 11:36:25 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 14/04/2025 11:36:25 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 14/04/2025 11:37:35 AM : Received optimal plan -> ['netflix_users_source.csv', {'associated_key': None}, {'standardiseFeatures': '```python\n{\n    ("User_ID",): ("id",),\n    ("Name",): ("first_name", "last_name"),\n    ("Age",): ("age",),\n    ("Country",): ("country_name",),\n    ("Subscription_Type",): ("subscription",),\n    ("Watch_Time_Hours",): ("watch_time_hours",),\n    ("Favorite_Genre",): ("favourite_genre",),\n    ("Last_Login",): ("last_access",)\n}\n```'}, 'missingValues/impute', 'duplicates', 'outliers/impute', {'standardiseValues': '```python\ndef transform_table(input_table):\n    # Extract header and data rows\n    header = input_table[0]\n    data_rows = input_table[1:]\n    \n    # Create a new table with the desired output header\n    output_header = ["id", "first_name", "last_name", "age", "country_name", \n                     "subscription", "watch_time_hours", "favourite_genre", "last_access"]\n    \n    output_table = [output_header]\n    \n    # Process each row\n    for row in data_rows:\n        # Create a dict for easier column access\n        row_dict = {header[i]: row[i] for i in range(len(header))}\n        \n        # Process name splitting\n        first_name = ""\n        last_name = ""\n        if row_dict["first_name"]:\n            name_parts = row_dict["first_name"].split()\n            if len(name_parts) >= 1:\n                first_name = name_parts[0]\n            if len(name_parts) >= 2:\n                last_name = name_parts[-1]\n        \n        # Format watch time hours - round to nearest 10\n        watch_time = ""\n        if row_dict["watch_time_hours"]:\n            try:\n                hours = float(row_dict["watch_time_hours"])\n                # Scale down very large values\n                if hours > 10000:  # If it\'s a very large number\n                    hours = hours / 100  # Scale down\n                watch_time = str(round(hours / 10) * 10)  # Round to nearest 10\n            except (ValueError, TypeError):\n                pass\n        \n        # Format date\n        formatted_date = ""\n        if row_dict["last_access"]:\n            try:\n                year, month, day = row_dict["last_access"].split("-")\n                months = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]\n                month_idx = int(month) - 1\n                month_name = months[month_idx]\n                formatted_date = f"{day}-{month_name}-{year[-2:]}"\n            except (ValueError, IndexError):\n                pass\n        \n        # Process age - ensure it\'s valid\n        age = ""\n        if row_dict["age"]:\n            try:\n                age_val = float(row_dict["age"])\n                if age_val > 100:  # If age is too high, normalize it\n                    age_val = age_val % 100\n                    if age_val == 0:\n                        age_val = 50\n                age = str(int(age_val))\n            except (ValueError, TypeError):\n                pass\n        \n        # Create new output row with processed values\n        new_row = [\n            "",  # id - will be assigned sequentially \n            first_name,\n            last_name,\n            age,\n            row_dict["country_name"],\n            row_dict["subscription"],\n            watch_time,\n            row_dict["favourite_genre"],\n            formatted_date\n        ]\n        \n        # Only add rows that have reasonable completeness\n        if any(new_row[1:]):  # If any value (besides id) is non-empty\n            output_table.append(new_row)\n    \n    # Assign sequential IDs and ensure we only use a small sample\n    sample_size = min(5, len(output_table) - 1)\n    output_table = output_table[:sample_size+1]  # Keep header + sample_size rows\n    \n    for i in range(1, len(output_table)):\n        output_table[i][0] = str(i)\n    \n    return output_table\n```'}]
root INFO - 14/04/2025 11:37:36 AM : Published the following metrics to Reporter : {'from': 'pre_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 40.234}, 'outliers': {'numerical_outliers_percent': 4.024}, 'duplicates': {'duplicate_rows_percent': 16.533}, 'dq': 0.797}}
kafka.conn INFO - 14/04/2025 11:37:36 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 14/04/2025 11:37:36 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 14/04/2025 11:37:36 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 14/04/2025 11:37:36 AM : Applied plan to file 'input\source\netflix_users_source.csv'
root INFO - 14/04/2025 11:37:36 AM : Successfully loaded the transformed file to '\output'
root INFO - 14/04/2025 11:37:36 AM : Published the following metrics to Reporter : {'from': 'post_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 13.333}, 'outliers': {'numerical_outliers_percent': 0.0}, 'duplicates': {'duplicate_rows_percent': 20.0}, 'dq': 0.978}}
kafka.producer.kafka INFO - 14/04/2025 11:37:36 AM : Closing the Kafka producer with 4294967.0 secs timeout.
kafka.conn INFO - 14/04/2025 11:37:36 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
kafka.conn INFO - 14/04/2025 11:37:36 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
