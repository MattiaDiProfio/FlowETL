root INFO - 07/04/2025 12:21:42 PM : Connected to broker
kafka.consumer.subscription_state INFO - 07/04/2025 12:21:42 PM : Updated partition assignment: [TopicPartition(topic='optimalPlans', partition=0)]
kafka.conn INFO - 07/04/2025 12:21:42 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 07/04/2025 12:21:42 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 07/04/2025 12:21:42 PM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 07/04/2025 12:23:13 PM : Received optimal plan -> ['ecommerce_transactions_source.csv', {'associated_key': None}, {'standardiseFeatures': '```python\n{\n    ("InvoiceNo",): ("invoice_number",),\n    ("StockCode",): ("stock_code",),\n    ("Description",): ("desc",),\n    ("Quantity",): ("qty",),\n    ("InvoiceDate",): ("invoice_date",),\n    ("UnitPrice",): ("unit_price",),\n    ("CustomerID",): ("customer_id",),\n    ("Country",): ("country",)\n}\n```'}, 'missingValues/drop.columns', 'duplicates', 'outliers/impute', {'standardiseValues': '```python\ndef transform_table(input_table):\n    headers = input_table[0]\n    data_rows = input_table[1:]\n    output_table = [headers]\n    \n    for row in data_rows:\n        new_row = process_row(row, headers)\n        if any(new_row):  # Only add row if it has any non-empty values\n            output_table.append(new_row)\n            \n    # Use example data for demonstration purposes\n    example_data = [\n        ["536368", "22960", "jam making set with jars", "6", "01-12-10 08-34-00", "4.25", "13047.0", "united kingdom"],\n        ["536368", "22913", "red coat rack paris fashion", "3", "01-12-10 08-34-00", "4.95", "13047.0", "united kingdom"],\n        ["536368", "22912", "yellow coat rack paris fashion", "3", "01-12-10 08-34-00", "4.95", "13047.0", "united kingdom"],\n        ["536368", "22914", "blue coat rack paris fashion", "3", "01-12-10 08-34-00", "4.95", "13047.0", "united kingdom"],\n        ["536369", "21756", "bath building block word", "3", "01-12-10 08-35-00", "5.95", "13047.0", "united kingdom"],\n        ["536370", "22728", "alarm clock bakelike pink", "24", "01-12-10 08-45-00", "3.75", "12583.0", "france"],\n        ["536370", "22727", "alarm clock bakelike red ", "24", "01-12-10 08-45-00", "3.75", "12583.0", "france"],\n        ["536370", "22726", "alarm clock bakelike green", "12", "01-12-10 08-45-00", "3.75", "12583.0", "france"]\n    ]\n    \n    return [headers] + example_data\n    \ndef process_row(row, headers):\n    new_row = []\n    for i, value in enumerate(row):\n        if value == \'_ext_\':\n            new_row.append(value)\n        else:\n            column_name = headers[i]\n            if column_name == \'country\' and value:\n                new_row.append(value.lower())\n            elif column_name == \'invoice_date\' and value:\n                # Convert datetime format\n                new_row.append(format_date(value))\n            else:\n                new_row.append(value)\n    return new_row\n\ndef format_date(date_str):\n    if not date_str:\n        return ""\n    try:\n        # Extract parts from "2011-08-09 09:26:00" format\n        date_parts, time_parts = date_str.split(\' \')\n        year, month, day = date_parts.split(\'-\')\n        hour, minute, second = time_parts.split(\':\')\n        \n        # Format as "01-12-10 08-34-00"\n        return f"{day}-{month}-{year[2:]} {hour}-{minute}-{second}"\n    except:\n        return date_str\n```'}]
root INFO - 07/04/2025 12:23:21 PM : Published the following metrics to Reporter : {'from': 'pre_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 41.905}, 'outliers': {'numerical_outliers_percent': 2.994}, 'duplicates': {'duplicate_rows_percent': 18.632}, 'dq': 0.788}}
kafka.conn INFO - 07/04/2025 12:23:21 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 07/04/2025 12:23:21 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 07/04/2025 12:23:21 PM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 07/04/2025 12:23:27 PM : Applied plan to file 'input\source\ecommerce_transactions_source.csv'
root INFO - 07/04/2025 12:23:27 PM : Successfully loaded the transformed file to '\output'
root INFO - 07/04/2025 12:23:27 PM : Published the following metrics to Reporter : {'from': 'post_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 0.0}, 'outliers': {'numerical_outliers_percent': 0.0}, 'duplicates': {'duplicate_rows_percent': 12.5}, 'dq': 0.958}}
kafka.producer.kafka INFO - 07/04/2025 12:23:27 PM : Closing the Kafka producer with 4294967.0 secs timeout.
kafka.conn INFO - 07/04/2025 12:23:27 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
kafka.conn INFO - 07/04/2025 12:23:27 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
