root INFO - 31/05/2025 02:57:44 PM : Connected to broker
kafka.consumer.subscription_state INFO - 31/05/2025 02:57:44 PM : Updated partition assignment: [TopicPartition(topic='optimalPlans', partition=0)]
kafka.conn INFO - 31/05/2025 02:57:44 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 31/05/2025 02:57:44 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 31/05/2025 02:57:44 PM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 31/05/2025 02:58:53 PM : Received optimal plan -> ['chemistry_source.csv', {'associated_key': None}, {'standardiseFeatures': '```python\n{\n    ("CHEMISTRY_ID",): ("CHEMISTRY_ID",),\n    ("CHEMISTRY_TYPE",): ("CHEMISTRY_TYPE",),\n    ("ASSAY_CATEGORY",): ("ASSAY_CATEGORY",),\n    ("ASSAY_NAME",): ("ASSAY_NAME",),\n    ("ACTIVITY",): ("ACTIVITY",),\n    ("UNITS",): ("UNITS",),\n    ("ASSAY_QUAL_RESULT",): ("ASSAY_QUAL_RESULT",),\n    ("CONCENTRATION",): ("CONCENTRATION",),\n    ("CONCENTRATION_UNITS",): ("CONCENTRATION_UNITS",),\n    ("ASSAY_DATE",): ("ASSAY_DATE",),\n    ("DEPARTMENT_ID",): ("DEPARTMENT_ID",),\n    ("BIOMASS_ID",): ("BIOMASS_ID",),\n    ("ORGANISM_ID",): ("ORGANISM_ID",),\n    ("SITE_ID",): ("SITE_ID",),\n    ("REGION",): ("REGION",),\n    ("LATITUDE",): ("LATITUDE",),\n    ("LONGITUDE",): ("LONGITUDE",),\n    ("PRODUCTION_MEDIA",): ("PRODUCTION_MEDIA",),\n    ("SOURCE_ID",): ("SOURCE_ID",),\n    ("SOURCE_TYPE",): ("SOURCE_TYPE",),\n    ("PERSON_ID",): ("PERSON_ID",),\n    ("COUNTRY",): ("COUNTRY",),\n    ("PHYLUM",): ("PHYLUM",),\n    ("COMMON_NAME",): ("COMMON_NAME",),\n    ("FAMILY",): ("FAMILY",),\n    ("GENUS",): ("GENUS",),\n    ("SPECIES",): ("SPECIES",)\n}\n```'}, 'missingValues/impute', 'duplicates', 'outliers/impute', {'standardiseValues': "```python\ndef transform_table(input_table):\n    # Create a copy of input table structure with first row (headers)\n    output_table = [input_table[0][:]]\n    \n    # Process each data row\n    for row in input_table[1:]:\n        # Create a new row with the same structure\n        new_row = row[:]\n        \n        # Handle the ACTIVITY field - convert to float if possible\n        activity = row[4]\n        if activity and activity != '_ext_':\n            # Check if the activity value contains a month abbreviation (like Mar-65)\n            if '-' in activity and len(activity.split('-')) == 2:\n                parts = activity.split('-')\n                if parts[0] in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']:\n                    # Convert month-value format to just the numeric part\n                    activity = parts[1]\n            \n            try:\n                new_row[4] = float(activity)\n            except ValueError:\n                # Keep as is if conversion fails\n                pass\n        \n        # Handle LONGITUDE - ensure it's converted to a number if possible\n        longitude = row[16]\n        if longitude and longitude != '_ext_':\n            if longitude.startswith('Dec-'):\n                # Handle Dec-82 format\n                try:\n                    new_row[16] = float(longitude.split('-')[1])\n                except (ValueError, IndexError):\n                    pass\n            else:\n                try:\n                    new_row[16] = float(longitude)\n                except ValueError:\n                    pass\n        \n        # Ensure CONCENTRATION is a number\n        if row[7] and row[7] != '_ext_':\n            try:\n                new_row[7] = float(row[7])\n            except ValueError:\n                pass\n                \n        # Ensure LATITUDE is a number\n        if row[15] and row[15] != '_ext_':\n            try:\n                new_row[15] = float(row[15])\n            except ValueError:\n                pass\n                \n        # Clean up family name if it ends with spaces\n        if row[24] and row[24] != '_ext_':\n            new_row[24] = row[24].strip()\n        \n        output_table.append(new_row)\n        \n    return output_table\n```"}]
root INFO - 31/05/2025 02:58:55 PM : Published the following metrics to Reporter : {'from': 'pre_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 10.717}, 'outliers': {'numerical_outliers_percent': 2.483}, 'duplicates': {'duplicate_rows_percent': 3.127}, 'dq': 0.946}}
kafka.conn INFO - 31/05/2025 02:58:55 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 31/05/2025 02:58:55 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 31/05/2025 02:58:55 PM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 31/05/2025 02:59:00 PM : Applied plan to file 'input\source\chemistry_source.csv'
root INFO - 31/05/2025 02:59:00 PM : Successfully loaded the transformed file to '\output'
root INFO - 31/05/2025 02:59:01 PM : Published the following metrics to Reporter : {'from': 'post_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 0.0}, 'outliers': {'numerical_outliers_percent': 12.969}, 'duplicates': {'duplicate_rows_percent': 0.002}, 'dq': 0.957}}
kafka.producer.kafka INFO - 31/05/2025 02:59:01 PM : Closing the Kafka producer with 4294967.0 secs timeout.
kafka.conn INFO - 31/05/2025 02:59:01 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
kafka.conn INFO - 31/05/2025 02:59:01 PM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
