root INFO - 14/04/2025 11:58:02 AM : Connected to broker
kafka.consumer.subscription_state INFO - 14/04/2025 11:58:02 AM : Updated partition assignment: [TopicPartition(topic='optimalPlans', partition=0)]
kafka.conn INFO - 14/04/2025 11:58:02 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 14/04/2025 11:58:02 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 14/04/2025 11:58:02 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 14/04/2025 11:59:09 AM : Received optimal plan -> ['social_media_posts_source.json', {'associated_key': None}, {'standardiseFeatures': '```python\n{ \n  ("language",): ("post_language",),\n  ("text",): ("post_content", "post_character_count"),\n  ("tags",): ("post_tags",),\n  ("engagement",): ("user_engagement",),\n  ("tone",): ("tone",),\n  ("line_count",): ()\n}\n```'}, 'missingValues/impute', 'duplicates', 'outliers/impute', {'standardiseValues': '```python\ndef transform_table(input_table):\n    # Extract headers and data\n    headers = input_table[0]\n    data = input_table[1:]\n    \n    # Initialize new table with headers\n    output_table = [\n        ["post_language", "post_character_count", "post_tags", "user_engagement", "post_content", "tone"]\n    ]\n    \n    for row in data:\n        new_row = []\n        \n        # Get values from input row\n        row_dict = {headers[i]: row[i] for i in range(len(headers))}\n        \n        # Transform post_language (always use English in output based on examples)\n        new_row.append("English")\n        \n        # Calculate post_character_count\n        post_content = row_dict.get(\'post_content\', \'\')\n        post_char_count = len(post_content)\n        new_row.append(post_char_count)\n        \n        # Transform post_tags: join with comma if list, otherwise use as is\n        post_tags = row_dict.get(\'post_tags\', [])\n        if isinstance(post_tags, list):\n            new_row.append(\', \'.join(post_tags))\n        else:\n            new_row.append(post_tags)\n        \n        # Transform user_engagement: keep as is (or convert to int if needed)\n        user_engagement = row_dict.get(\'user_engagement\', 0)\n        if isinstance(user_engagement, str) and user_engagement != \'_ext_\':\n            try:\n                user_engagement = int(float(user_engagement))\n            except ValueError:\n                user_engagement = 0\n        new_row.append(user_engagement)\n        \n        # Transform post_content: keep as is\n        new_row.append(post_content)\n        \n        # Transform tone: convert to lowercase\n        tone = row_dict.get(\'tone\', \'\')\n        if isinstance(tone, str) and tone != \'_ext_\':\n            tone = tone.lower()\n        new_row.append(tone)\n        \n        output_table.append(new_row)\n    \n    return output_table\n```'}]
root INFO - 14/04/2025 11:59:09 AM : Published the following metrics to Reporter : {'from': 'pre_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 0.0}, 'outliers': {'numerical_outliers_percent': 19.167}, 'duplicates': {'duplicate_rows_percent': 1.667}, 'dq': 0.942}}
kafka.conn INFO - 14/04/2025 11:59:09 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 14/04/2025 11:59:09 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 14/04/2025 11:59:09 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 14/04/2025 11:59:09 AM : Applied plan to file 'input\source\social_media_posts_source.json'
root INFO - 14/04/2025 11:59:09 AM : Successfully loaded the transformed file to '\output'
root INFO - 14/04/2025 11:59:09 AM : Published the following metrics to Reporter : {'from': 'post_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 0.0}, 'outliers': {'numerical_outliers_percent': 6.667}, 'duplicates': {'duplicate_rows_percent': 1.667}, 'dq': 0.983}}
kafka.producer.kafka INFO - 14/04/2025 11:59:09 AM : Closing the Kafka producer with 4294967.0 secs timeout.
kafka.conn INFO - 14/04/2025 11:59:09 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
kafka.conn INFO - 14/04/2025 11:59:09 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
