root INFO - 14/04/2025 11:56:09 AM : Connected to broker
kafka.consumer.subscription_state INFO - 14/04/2025 11:56:09 AM : Updated partition assignment: [TopicPartition(topic='optimalPlans', partition=0)]
kafka.conn INFO - 14/04/2025 11:56:09 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 14/04/2025 11:56:09 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 14/04/2025 11:56:09 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 14/04/2025 11:57:25 AM : Received optimal plan -> ['recipes_source.json', {'associated_key': None}, {'standardiseFeatures': '```python\n{("id",): ("recipe_id",), ("cuisine",): ("cuisine",), ("ingredients",): ("ingredients_list",)}\n```'}, 'missingValues/impute', 'duplicates', 'outliers/impute', {'standardiseValues': 'def transform_table(input_table):\n    header = input_table[0]\n    data_rows = input_table[1:]\n    output_table = []\n    \n    # Add header to output table\n    output_table.append(["cuisine", "recipe_id", "ingredients_list"])\n    \n    for row in data_rows:\n        # Extract the values from input row\n        recipe_id_idx = header.index("recipe_id")\n        cuisine_idx = header.index("cuisine")\n        ingredients_idx = header.index("ingredients_list")\n        \n        recipe_id = row[recipe_id_idx]\n        cuisine = row[cuisine_idx]\n        ingredients = row[ingredients_idx]\n        \n        # Transform the ingredients list into a string with pipe separators\n        if isinstance(ingredients, list):\n            ingredients_str = "| ".join(ingredients)\n        else:\n            ingredients_str = str(ingredients)\n        \n        # Create output row\n        output_row = [cuisine, recipe_id, ingredients_str]\n        output_table.append(output_row)\n    \n    return output_table'}]
root INFO - 14/04/2025 11:57:26 AM : Published the following metrics to Reporter : {'from': 'pre_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 0.0}, 'outliers': {'numerical_outliers_percent': 0.0}, 'duplicates': {'duplicate_rows_percent': 0.003}, 'dq': 1.0}}
kafka.conn INFO - 14/04/2025 11:57:26 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 14/04/2025 11:57:26 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 14/04/2025 11:57:26 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root ERROR - 14/04/2025 11:57:26 AM : Error occured during the transform or load phase : 'NoneType' object is not subscriptable
root INFO - 14/04/2025 11:57:26 AM : Published the following metrics to Reporter : {'from': 'post_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 0.0}, 'outliers': {'numerical_outliers_percent': 0.0}, 'duplicates': {'duplicate_rows_percent': 0.0}, 'dq': 0.0}}
kafka.producer.kafka INFO - 14/04/2025 11:57:26 AM : Closing the Kafka producer with 4294967.0 secs timeout.
kafka.conn INFO - 14/04/2025 11:57:26 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
kafka.conn INFO - 14/04/2025 11:57:26 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
