root INFO - 07/04/2025 11:45:46 AM : Connected to broker
kafka.consumer.subscription_state INFO - 07/04/2025 11:45:46 AM : Updated partition assignment: [TopicPartition(topic='optimalPlans', partition=0)]
kafka.conn INFO - 07/04/2025 11:45:46 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 07/04/2025 11:45:46 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 07/04/2025 11:45:46 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 07/04/2025 11:46:59 AM : Received optimal plan -> ['amazon_stock_data_source.csv', {'associated_key': None}, {'standardiseFeatures': '```python\n{\n    ("date",): ("date",),\n    ("open",): ("open_price",),\n    ("high",): ("daily_high",),\n    ("low",): ("daily_low",),\n    ("close",): ("close_price",),\n    ("volume",): ("trade_volume_millions",),\n    ("adj_close",): ()\n}\n```'}, 'missingValues/drop.columns', 'duplicates', 'outliers/impute', {'standardiseValues': '```python\ndef transform_table(input_table):\n    # Extract headers and data rows\n    headers = input_table[0]\n    data_rows = input_table[1:]\n    \n    # Create output table with headers\n    output_table = [headers.copy()]\n    \n    # Process each data row\n    for row in data_rows:\n        # Skip rows with insufficient data\n        if not any(cell for cell in row):\n            continue\n            \n        new_row = []\n        for i, header in enumerate(headers):\n            # Check if the current value is \'_ext_\'\n            if row[i] == \'_ext_\':\n                new_row.append(\'_ext_\')\n                continue\n                \n            # Process each column according to its type\n            if header == \'date\':\n                # Format date as YYYY/MM/DD\n                if row[i]:\n                    # Extract date part (YYYY-MM-DD) and reformat\n                    date_parts = row[i].split(\' \')[0].split(\'-\')\n                    if len(date_parts) == 3:\n                        new_row.append(f"{date_parts[0]}/{date_parts[1]}/{date_parts[2]}")\n                    else:\n                        new_row.append(\'\')\n                else:\n                    new_row.append(\'\')\n            else:\n                # Process numeric columns - clean and format\n                if row[i]:\n                    # Convert to float and format with 3 decimal places\n                    try:\n                        value = float(row[i])\n                        if header == \'trade_volume_millions\':\n                            # Convert to millions if needed\n                            if value > 1000000:  # If the number is already in full units\n                                value = value / 1000000\n                        new_row.append(f"{value:.3f}")\n                    except ValueError:\n                        new_row.append(\'\')\n                else:\n                    new_row.append(\'\')\n        \n        # Only add rows that have been properly processed\n        if all(cell != \'\' for cell in new_row):\n            output_table.append(new_row)\n            \n    return output_table\n```'}]
root INFO - 07/04/2025 11:46:59 AM : Published the following metrics to Reporter : {'from': 'pre_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 40.182}, 'outliers': {'numerical_outliers_percent': 2.287}, 'duplicates': {'duplicate_rows_percent': 16.451}, 'dq': 0.804}}
kafka.conn INFO - 07/04/2025 11:46:59 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
kafka.conn INFO - 07/04/2025 11:46:59 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.
kafka.conn INFO - 07/04/2025 11:46:59 AM : <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
root INFO - 07/04/2025 11:46:59 AM : Applied plan to file 'input\source\amazon_stock_data_source.csv'
root INFO - 07/04/2025 11:46:59 AM : Successfully loaded the transformed file to '\output'
root INFO - 07/04/2025 11:46:59 AM : Published the following metrics to Reporter : {'from': 'post_etl_pipeline', 'contents': {'missing': {'missing_cells_percent': 0.0}, 'outliers': {'numerical_outliers_percent': 0.0}, 'duplicates': {'duplicate_rows_percent': 0.027}, 'dq': 1.0}}
kafka.producer.kafka INFO - 07/04/2025 11:46:59 AM : Closing the Kafka producer with 4294967.0 secs timeout.
kafka.conn INFO - 07/04/2025 11:46:59 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
kafka.conn INFO - 07/04/2025 11:46:59 AM : <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. 
